---
sidebar_position: 2
sidebar_label: 'Get Started with Dendro'
---
import NonPropagatingCheckbox from '@site/src/components/NonPropagatingCheckbox/NonPropagatingCheckbox';

# Get Started with Dendro

In this tutorial we will go through all the steps needed to run your first data processing job on Dendro, from scratch:

1. Register and start a Compute Resource hosted on [dandihub](https://hub.dandiarchive.org/).
2. Install an app for spike sorting using the [Mountainsort5](https://github.com/flatironinstitute/mountainsort5) algorithm.
3. Create a project and import assets from [DANDI Archive](https://dandiarchive.org/).
4. Run jobs.
5. Visualize results on [Neurosift](https://neurosift.app/).


## Register and start a Compute Resource
First, you'll need to register a Compute Resource. Compute Resources are the compute environments where your Dendro jobs will run, you can read about it in more details [here](/docs/category/compute-resource).

Setting up a Compute Resource is a one-time step, and you can re-use the same Compute Resource later on for all your projects.
For this tutorial, we will setup a Compute Resource on [dandihub](https://hub.dandiarchive.org/), a cloud-based platform that provides a free environment for running lightweight Dendro jobs.

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>1. Start an instance on <a href="https://hub.dandiarchive.org/">dandihub</a>.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

We suggest a `Medium` instance, which has 12 CPUs and 32GB of memory. This might take a few minutes to start.

![Start a dandihub instance](/img/tutorial_dandi/1_1_start_instance.png)

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>2. Start a terminal session.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Within the Jupyter Lab environment, start a `Terminal`.

![Start a dandihub instance](/img/tutorial_dandi/1_2_start_terminal.png)

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>3. Setup the environment for Dendro using the terminal.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Create a new directory and navigate to it:
```bash
mkdir dendro && cd dendro
```

Install Dendro:
```bash
pip install dendro[compute_resource]
```

Set the environment variable `CONTAINER_METHOD` to `apptainer`:
```bash
export CONTAINER_METHOD=apptainer
```

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>4. Register a Compute Resource using the terminal.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

```bash
dendro register-compute-resource
```

Click on the link provided, which will redirect you to the Dendro UI in a new browser tab.
Choose a name for the compute resource, e.g. `tutorial-cr`, and click on `Register`.

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>5. Start the Compute Resource using the terminal.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

You can now start the Compute Resource using the terminal.
```bash
dendro start-compute-resource
```

You sould see the message `Compute resource is running`.

Obs.: You can stop the Compute Resource with `CTRL+C`.

</details>

✅ Congratulations! You have successfully registered and started a Compute Resource for Dendro platform.


## Install apps

Dendro encapsulates advanced data processing algorithms into apps. Apps are installed to a Compute Resource, and can be used in multiple projects.

With your Compute Resource up and running, you can now install data processing apps to it, using the Dendro UI:

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>1. Select the Compute Resource.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Click on `Configure compute resources`, at the top right corner.

![Configure compute resources](/img/tutorial_dandi/2_1_configure_compute_resources.png)

Then choose the Compute Resource you just created.

![Choose compute resource](/img/tutorial_dandi/2_2_choose_compute_resource.png)

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>2. Add an app.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Under `Apps` section, click on `Add app`. You will be prompted to enter the app's name and the URL pointing to the spec file.

For this tutorial, we will use the [SpikeInterface Pipeline - Mountainsort5](https://github.com/catalystneuro/si-dendro-apps) app to perform spike sorting on an electrophysiology dataset.

The app spec file is located at `https://github.com/catalystneuro/si-dendro-apps/blob/main/si_mountainsort5/spec.json`.

![Add app](/img/tutorial_dandi/2_3_add_app.png)

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>3. Verify that the app was successfully installed.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Looking back at the dandihub terminal, you should see a success message indicating that the app was successfully installed, similar to the following:

```bash
Loading app https://github.com/catalystneuro/si-dendro-apps/blob/main/si_mountainsort5/spec.json
URL: https://raw.githubusercontent.com/catalystneuro/si-dendro-apps/main/si_mountainsort5/spec.json?cachebust=xxxxxxxxxxxxxxxxxxxxxxxxx
  processors: spikeinterface_pipeline_mountainsort5
```

</details>

✅ Great! You have successfully installed an app to your Compute Resource. This means you can now run jobs using this app, in this Compute Resource.


## Create projects and import dandisets

In Dendro, projects are the main organizational unit for a given collection of imported data and outputs from jobs. A project can contain multiple dandisets and use different compute resources.

Let's create a project and choose a Compute Resource for it:

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>1. Create a new project.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Click on `Manage projects`, at the top right corner:

![Manage projects](/img/tutorial_dandi/3_1_manage_projects.png)

At the projects management page, click on `Create a new project` and choose a name for it, e.g. `tutorial-project`. You should be redirected to the new project's page.
</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>2. Select a Compute Resource for the project.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

At the project’s page, under `Compute Resource`, click on `Select a different compute resource for this project`, and select the compute resource you just created in the previous steps.

![Select Compute Resource](/img/tutorial_dandi/3_2_select_cr.png)

</details>


Projects can contain multiple dandisets, which can be imported from DANDI Archive directly through the Dendro UI. Let's import a dandiset to your Dendro project:

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>3. Add a dandiset to the project.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Click on `DANDI Import`, at the left side navigation menu, then click on `Add new dandiset to project`. Enter the dandiset ID, e.g. `000409`, and click on `OK`.

![DANDI Import](/img/tutorial_dandi/3_3_import_dandiset.gif)

Now all the assets from this dandiset will be available to be imported into your project.

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>4. Import assets from a dandiset.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

A dandiset can contain hundreds of assets, and you need to select which ones you want to import to your project. For this tutorial, we will import a single NWB file from the dandiset `000409`.

Choose the `sub-CSHL045/sub-CSHL045_ses-46794e05-3f6a-4d35-afb3-9165091a5a74_behavior+ecephys+image.nwb` file and click on `Import selected assets`.

![Import assets](/img/tutorial_dandi/3_4_import_asset.png)

</details>

✅ Well done! You have successfully created a project and imported a dandiset asset to it. Now it's time to run a job using this file.

## Run Dendro jobs

Up to this point, you have:
- Registered and started a Compute Resource
- Installed a spike sorting app to the Compute Resource
- Created a project and imported a dandiset asset to it

Next, we will run a spike sorting job on the imported file:

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>1. Select the file with the source data.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Navigate to the `Files` page, select the file you just imported, and click on `Spike sorting`.

Next, click on `spikeinterface_pipeline_mountainsort5` processor, this should open the job configuration screen.

![Select file](/img/tutorial_dandi/4_1_select_file.gif)

</details>

At this point, you can take some time to explore the vast number of parameters available for the job.

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>2. Explore the job parameters.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

The left side form contains the job parameters:
- `Run method` - defines where the job will run.
- `Number of CPUs` - the number of CPUs to be used by the job.
- `Number of GPUs` - the number of GPUs to be used by the job.
- `Memory` - the amount of memory to be used by the job.
- `Time` - the maximum time the job can run.

For this tutorial, you should leave the default values for these parameters.

Change the `Description string in output file name` to something easier to identify the job result files later on, e.g. `tutorial-ms5`.

![Job configurations](/img/tutorial_dandi/4_2_job_configurations.png)

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>3. Explore the processor parameters.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

The right side form contains the processor parameters.

For the `spikeinterface_pipeline_mountainsort5` processor there are many parameters that can be configured to customize the spike sorting job. Here are some examples:
- `recording_context` contains parameters for the interface with the input file. E.g. you can make this job just a quick try run by checking `stub_test`.
- `preprocessing_context` contains parameters for the preprocessing steps, including signal filtering, detection of bad channels and motion correction.
- `spikesorting_context` contains parameters for the spike sorting algorithm
- `postprocessing_context` contains parameters for postprocessing the sorting results, including quality metrics extraction.
- `curation_context` allows you to enter a custom query for curation of the sorting results.

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>4. Load parameters from file.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Dendro job parameters can be saved to a file and loaded later. This is useful for sharing configurations between users or for running the same job multiple times.

For this tutorial, you can download the parameters file from [here](https://raw.githubusercontent.com/flatironinstitute/dendro-docs/main/extra_assets/tutorial-ms5.json).

Click on `Load parameters` and choose the file you just downloaded.

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>5. Submit the job.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Click on `Submit job(s)`:

![Submit job](/img/tutorial_dandi/4_3_submit_job.png)

At the Compute Resource terminal, you should see a logged message indicating that the job was successfully submitted:

```bash
Starting job xxxxxxxxxxxxx spikeinterface_pipeline_mountainsort5
Running: apptainer exec ...
```

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>6. Follow the job progress.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

You can follow the job's progress in real time. Navigate to the `Jobs` page and select the job you just submitted.

![Check job](/img/tutorial_dandi/4_4_check_job.png)

A panel will open with the job's details, including:
- General information and status
- Inputs and output files
- Resource utilization (updated in real time)
- Console output logs (updated in real time)

</details>

✅ Bravo! You have successfully submitted a spike sorting job on a public electrophysiology dataset!


## Visualize results

Results are saved as NWB files that can be found under the `generated` folder of the `Files` page. You can visualize and explore the results in multiple ways:

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>1. Check results file information in Dendro.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Clicking on the output NWB file will open a tab with general information:

![File info](/img/tutorial_dandi/5_1_file_info.png)

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>2. Open results file in Python.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Opening the NWB file is a convenient way to explore the results of the spike sorting job in a Python environment.

Click on `Load NWB file in Python`, copy the code snippet and run it in a Jupyter notebook on your dandihub instance or on own machine.

This will require the following Python packages to be installed:
- h5py
- pynwb
- dendro

```bash
pip install h5py pynwb dendro
```

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>3. Open results file in Neurosift.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

[Neurosift](https://neurosift.app/) is a web-based platform for visualization of NWB files. It is tightly integrated with Dendro, so you can easily visualize the results of your spike sorting jobs.

Neurosift is capable of combining multiple NWB files into a single visualization, which is useful for exploring the results of Dendro jobs together with the original raw data.

To open the results in Neurosift, mark the checkbox of the two files (the imported and the generated) and click on `Open in Neurosift`:

![File info](/img/tutorial_dandi/5_3_open_file_neurosift.png)

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>4. Explore results file data on Neurosift. [part 1]</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

At Neurosift main page, you will see the files metadata at the left side, and the data visualization options at the right side. Neurosift is able to combine the original file data, containing the raw electrophysiology and trials data, with the generated file data, containing the spike sorting results.

Expand the `intervals` tab and check the the outer checkbox, then expand the `processing/ecephys` tab and check the outer checkbox. Next, click on `Open PSTH for selected items`:

![Neurosift](/img/tutorial_dandi/5_4_open_psth.png)

At the PSTH tab, you can see the spike sorting results aligned with the session trials, including the spike raster plot and the peri-stimulus time histogram. Take some time to explore the data, select different units and alignments. Can you find any interesting responses?

![PSTH](/img/tutorial_dandi/5_4_psth.png)

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>5. Explore results file data on Neurosift. [part 2]</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Neurosift provides a wide range of visualization options for exploring the data. Take some time to explore the different tabs and options! Here are some examples of what you can do.

The spikes waveforms plot:

![Waveforms](/img/tutorial_dandi/5_5_waveforms.png)

The spiking raster plot:

![Raster](/img/tutorial_dandi/5_5_raster.png)

</details>


✅ Now you know how to visualize the results of your Dendro jobs!


## Upload results to DANDI Archive

Dendro allows you to upload the results of your jobs back to DANDI Archive. This is a great way to share your data processing results with the scientific community.

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>1. Select the file to be uploaded.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Navigate to the `Files` page, select the file you want to upload, and click on `Upload to DANDI`.

<!-- ![Upload to DANDI](/img/tutorial_dandi/6_1_upload_dandi.png) -->

</details>