---
sidebar_position: 2
sidebar_label: 'Get Started with Dendro'
---
import NonPropagatingCheckbox from '@site/src/components/NonPropagatingCheckbox/NonPropagatingCheckbox';

# Get Started with Dendro

In this tutorial we will go through all the steps needed to run your first data processing job on Dendro, from scratch:

1. Register and start a Compute Resource hosted on [dandihub](https://hub.dandiarchive.org/).
2. Install an app for spike sorting using the [Mountainsort5](https://github.com/flatironinstitute/mountainsort5) algorithm.
3. Create a project and import assets from [DANDI Archive](https://dandiarchive.org/).
4. Run jobs.
5. Visualize results on [Neurosift](https://neurosift.app/).


## Register and start a Compute Resource
First, you'll need to register a Compute Resource. Compute Resources are the compute environments where your Dendro jobs will run, you can read about it in more details [here](/docs/category/compute-resource).

Setting up a Compute Resource is a one-time step, and you can re-use the same Compute Resource later on for all your projects.
For this tutorial, we will setup a Compute Resource on [dandihub](https://hub.dandiarchive.org/), a cloud-based platform that provides a free environment for running lightweight Dendro jobs.

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>1. Start an instance on <a href="https://hub.dandiarchive.org/">dandihub</a>.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

We suggest a `Medium` instance, which has 12 CPUs and 32GB of memory. This might take a few minutes to start.

![Start a dandihub instance](/img/tutorial_dandi/1_1_start_instance.png)

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>2. Start a terminal session.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Within the Jupyter Lab environment, start a `Terminal`.

![Start a dandihub instance](/img/tutorial_dandi/1_2_start_terminal.png)

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>3. Setup the environment for Dendro using the terminal.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Create a new directory and navigate to it:
```bash
mkdir dendro && cd dendro
```

Install Dendro:
```bash
pip install dendro[compute_resource]
```

Set the environment variable `CONTAINER_METHOD` to `apptainer`:
```bash
export CONTAINER_METHOD=apptainer
```

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>4. Register a Compute Resource using the terminal.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

```bash
dendro register-compute-resource
```

Click on the link provided, which will redirect you to the Dendro UI in a new browser tab.
Choose a name for the compute resource, e.g. `tutorial-cr`, and click on `Register`.

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>5. Start the Compute Resource using the terminal.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

You can now start the Compute Resource using the terminal.
```bash
dendro start-compute-resource
```

You sould see the message `Compute resource is running`.

Obs.: You can stop the Compute Resource with `CTRL+C`.

</details>

✅ Congratulations! You have successfully registered and started a Compute Resource for Dendro platform.


## Install apps

Dendro encapsulates advanced data processing algorithms into apps. Apps are installed to a Compute Resource, and can be used in multiple projects.

With your Compute Resource up and running, you can now install data processing apps to it, using the Dendro UI:

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>1. Select the Compute Resource.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Click on `Configure compute resources`, at the top right corner.

![Configure compute resources](/img/tutorial_dandi/2_1_configure_compute_resources.png)

Then choose the Compute Resource you just created.

![Choose compute resource](/img/tutorial_dandi/2_2_choose_compute_resource.png)

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>2. Add an app.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Under `Apps` section, click on `Add app`. You will be prompted to enter the app's name and the URL pointing to the spec file.

For this tutorial, we will use the [SpikeInterface Pipeline - Mountainsort5](https://github.com/catalystneuro/si-dendro-apps) app to perform spike sorting on an electrophysiology dataset.

The app spec file is located at `https://github.com/catalystneuro/si-dendro-apps/blob/main/si_mountainsort5/spec.json`.

![Add app](/img/tutorial_dandi/2_3_add_app.png)

</details>

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>3. Verify that the app was successfully installed.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Looking back at the dandihub terminal, you should see a success message indicating that the app was successfully installed, similar to the following:

```bash
Loading app https://github.com/catalystneuro/si-dendro-apps/blob/main/si_mountainsort5/spec.json
URL: https://raw.githubusercontent.com/catalystneuro/si-dendro-apps/main/si_mountainsort5/spec.json?cachebust=xxxxxxxxxxxxxxxxxxxxxxxxx
  processors: spikeinterface_pipeline_mountainsort5
```

</details>

✅ Great! You have successfully installed an app to your Compute Resource. This means you can now run jobs using this app, in this Compute Resource.


## Create projects and import dandisets

In Dendro, projects are the main organizational unit for a given collection of imported data and outputs from jobs. A project can contain multiple dandisets and use different compute resources.

Let's create a project and choose a Compute Resource for it:

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>1. Create a new project.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Click on `Manage projects`, at the top right corner:

![Manage projects](/img/tutorial_dandi/3_1_manage_projects.png)

At the projects management page, click on `Create a new project` and choose a name for it, e.g. `tutorial-project`. You should be redirected to the new project's page.
</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>2. Select a Compute Resource for the project.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

At the project’s page, under `Compute Resource`, click on `Select a different compute resource for this project`, and select the compute resource you just created in the previous steps.

![Select Compute Resource](/img/tutorial_dandi/3_2_select_cr.png)

</details>


Projects can contain multiple dandisets, which can be imported from DANDI Archive directly through the Dendro UI. Let's import a dandiset to your Dendro project:

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>3. Add a dandiset to the project.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Click on `DANDI Import`, at the left side navigation menu, then click on `Add new dandiset to project`. Enter the dandiset ID, e.g. `000409`, and click on `OK`.

![DANDI Import](/img/tutorial_dandi/3_3_import_dandiset.gif)

Now all the assets from this dandiset will be available to be imported into your project.

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>4. Import assets from a dandiset.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

A dandiset can contain hundreds of assets, and you need to select which ones you want to import to your project. For this tutorial, we will import a single NWB file from the dandiset `000409`.

Choose the `sub-CSHL045/sub-CSHL045_ses-46794e05-3f6a-4d35-afb3-9165091a5a74_behavior+ecephys+image.nwb` file and click on `Import selected assets`.

![Import assets](/img/tutorial_dandi/3_4_import_asset.png)

</details>

✅ Well done! You have successfully created a project and imported a dandiset asset to it. Now it's time to run a job using this file.

## Run Dendro jobs

Up to this point, you have:
- Registered and started a Compute Resource
- Installed a spike sorting app to the Compute Resource
- Created a project and imported a dandiset asset to it

Next, we will run a spike sorting job on the imported file:

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>1. Select the file with the source data.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Navigate to the `Files` page, select the file you just imported, and click on `Spike sorting`.

Next, click on `spikeinterface_pipeline_mountainsort5` processor, this should open the job configuration screen.

![Select file](/img/tutorial_dandi/4_1_select_file.gif)

</details>

At this point, you can take some time to explore the vast number of parameters available for the job.

<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>2. Explore the job parameters.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

The left side form contains the job parameters:
- `Run method` - defines where the job will run.
- `Number of CPUs` - the number of CPUs to be used by the job.
- `Number of GPUs` - the number of GPUs to be used by the job.
- `Memory` - the amount of memory to be used by the job.
- `Time` - the maximum time the job can run.

For this tutorial, you should leave the default values for these parameters.

![Job configurations](/img/tutorial_dandi/4_2_job_configurations.png)

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>3. Explore the processor parameters.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

The right side form contains the processor parameters.

For the `spikeinterface_pipeline_mountainsort5` processor there are many parameters that can be configured to customize the spike sorting job. Here are some examples:
- `recording_context` contains parameters for the interface with the input file. E.g. you can make this job just a quick try run by checking `stub_test`.
- `preprocessing_context` contains parameters for the preprocessing steps, including signal filtering, detection of bad channels and motion correction.
- `spikesorting_context` contains parameters for the spike sorting algorithm
- `postprocessing_context` contains parameters for postprocessing the sorting results, including quality metrics extraction.
- `curation_context` allows you to enter a custom query for curation of the sorting results.

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>4. Load parameters from file.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Dendro job parameters can be saved to a file and loaded later. This is useful for sharing configurations between users or for running the same job multiple times.

For this tutorial, you can download the parameters file from [here](https://raw.githubusercontent.com/flatironinstitute/dendro-docs/dev/extra_assets/tutorial-ms5.json).

Click on `Load parameters` and choose the file you just downloaded.

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>5. Submit the job.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

Click on `Submit job(s)`:

![Submit job](/img/tutorial_dandi/4_3_submit_job.png)

At the Compute Resource terminal, you should see a logged message indicating that the job was successfully submitted:

```bash
Starting job xxxxxxxxxxxxx spikeinterface_pipeline_mountainsort5
Running: apptainer exec ...
```

</details>


<details>
  <summary>
    <span style={{display: "flex", justifyContent: "space-between", alignItems: "center"}}>
        <div>6. Follow the job progress.</div>
        <NonPropagatingCheckbox style={{marginLeft: "auto"}} />
    </span>
  </summary>

You can follow the job's progress in real time. Navigate to the `Jobs` page and select the job you just submitted.

![Check job](/img/tutorial_dandi/4_4_check_job.png)

A panel will open with the job's details, including:
- General information and status
- Inputs and output files
- Resource utilization (updated in real time)
- Console output logs (updated in real time)

</details>

✅ Bravo! You have successfully submitted a spike sorting job on a public electrophysiology dataset!


## Visualize results on Neurosift

[Neurosift](https://neurosift.app/) is a web-based platform for visualization of NWB files. It is tightly integrated with Dendro, so you can easily visualize the results of your spike sorting jobs.